{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 350 book 2\n",
    "\n",
    "This is a jupyter notebook illustrating the peak detection, spike sorting by k-means clustering, and frequency analysis of extracellular data from an abf file.\n",
    "\n",
    "It requires installation of neo (pip install neo).\n",
    "\n",
    "To execute each cell and advance to the next, hit shift+enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all has gone well this week, you have two different and quite interesting datasets to play with for your\n",
    "next figure. There are many different sorts of analyses you could perform for each of the datasets –\n",
    "refer to our prompts on lab manual pages 27-8 and the crawdad prompts on pages 89 and 91.\n",
    "\n",
    "Whether you are trying to analyze changes in synaptic strength from your plasticity experiments, or do\n",
    "some spike sorting and see which spike classes correspond the junction potentials in your paired\n",
    "recording, there is a core set of analysis tools it would be handy to have at your disposal.\n",
    "\n",
    "__Peak detection__ refers to the identification of the time coordinate and amplitude of spikes or junction\n",
    "potentials. With those coordinates, you are able to do spike sorting as well as frequency analysis.\n",
    "__Spike sorting__ refers to separating your spikes into classes or “units” corresponding to the activity of\n",
    "different individual neurons. (Recall that the crayfish sN3 has 6 dominant axons.) There are many ways\n",
    "to sort – it can be as crude as “eyeballing it” or involve comparing the specific shapes of each action\n",
    "potential. The method we present here involves taking your peaks identified by thresholding and then\n",
    "__clustering__ them.[1] You can also do frequency analysis: if your frequency is stable over time, then it may\n",
    "be adequate to report the average firing rate over time; if you’re considering changes in frequency, it\n",
    "is most sensible to look at the __instantaneous firing rate__ (IFR). The IFR is defined as the reciprocal of the\n",
    "inter-spike interval, which is the time between two successive spikes.\n",
    "\n",
    "__Disclaimer__: This document does not represent the scope of analysis we expect you to perform for\n",
    "your next figure. We would much prefer you to give some thought to this toolbox of techniques in\n",
    "light of the data you collected this week, and to be selective about what you choose to implement,\n",
    "than to have you paste all the commands without understanding what you’re actually doing.\n",
    "\n",
    "***\n",
    "\n",
    "[1] We illustrate this approach with k-means clustering because it’s quick and easy. It can be argued that\n",
    "other approaches are better for 1-d data (e.g., natural break segmentation), but we’ll leave that to you\n",
    "to sort out if you become interested. All of these approaches have limitations, first among which is that\n",
    "some of the axons in sN3 have very similar diameters, which makes separating them by amplitude\n",
    "difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import neo\n",
    "from scipy.signal import medfilt\n",
    "from scipy.ndimage import label\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "data_file = 'sample2.abf'\n",
    "r = neo.AxonIO(filename=data_file)\n",
    "block = r.read_block()\n",
    "segment = block.segments[0]\n",
    "\n",
    "nerve,muscle = segment.analogsignals\n",
    "# this tutorial supposes a two channel recording with nerve and muscle data\n",
    "# (even though the steps are only looking at the nerve record)\n",
    "# You should figure out which of these tools make sense for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the length of a data file, I often tend to narrow my scope for the first pass of analysis. If\n",
    "things go smoothly and you want to increase your statistical power, you can then go back and run the\n",
    "rest of your data through your scripts once you have them polished. I also like to avoid the first half-second\n",
    "or so when signal filters are on, so I don’t have to worry about the time it takes for the signal to\n",
    "reach zero. 100k samples at 10kHz is 10s of data, which is a quantity I find workable most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerve = np.asarray(nerve[100001:200000]) # crop the data for first-pass analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will median filter to adjust for slow drift in your baseline.  This step is optional, and you can feel free to skip it if it makes your computer hang up for longer than you would like.\n",
    "\n",
    "You can uncomment the plot commands to observe the difference and see that the filtering will give you higher confidence of spike amplitudes called during peak detection. (I consider this good practice for almost all of the steps in these tutorials.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adjust for baseline drift; may take a bit of time, especially for a large file\n",
    "\n",
    "#pl.plot(nerve)\n",
    "baseline = medfilt(nerve, kernel_size=801)\n",
    "nerve -= baseline\n",
    "#pl.plot(nerve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak detection is done in two steps.  First we tag all of the data that lies above a threshold.  Here the threshold is defined as 2.5 SD above the average signal from data.  You should play with this value and see how it affects your capacity to detect what you perceive by eye to be action potentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the values in the signal that pass some threshold\n",
    "direction = 1 # 1 for upward, -1 for downward\n",
    "n_std = 2.5\n",
    "thresh = nerve.mean() + nerve.std() * n_std\n",
    "above_thresh = direction * nerve > thresh    # boolean array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the local maxima in the segments above threshold.  This script won't find overlapping APs if the signal doesn't drop to baseline in between them.  I'll leave it to you to think about how to address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the above_thresh signal into connected segments\n",
    "labs,nlabs = label(above_thresh)\n",
    "\n",
    "peak_idxs = [] # stores the indices of peaks\n",
    "\n",
    "# iterate through each segment\n",
    "for l in range(1,nlabs+1):\n",
    "    \n",
    "    # find the indices of this segment\n",
    "    idxs = np.where(labs==l)[0]\n",
    "    \n",
    "    # extract the signal values at these idxs\n",
    "    vals = nerve[idxs]\n",
    "    \n",
    "    # select the index corresponding to the peak signal value\n",
    "    peak_idx = idxs[np.argmax(vals)]\n",
    "    \n",
    "    peak_idxs.append(peak_idx)\n",
    "\n",
    "peak_heights = nerve[peak_idxs] # we want the voltage at those peaks, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the discovered peaks\n",
    "pl.figure(1)\n",
    "pl.plot(nerve)\n",
    "pl.plot(peak_idxs, peak_heights, 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will segment our peaks into units using k-means clustering.  Play with k and assess the performance of the sorting.\n",
    "\n",
    "Recall that several of the AP units occur around the same height, so naive clustering of any sort may not properly segment them.  How could you get around this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the distribution of peak values (might help you see clusters, and thus select k for k-means)\n",
    "pl.figure(2)\n",
    "pl.hist(peak_heights, bins=100)\n",
    "pl.xlabel('AP magnitude')\n",
    "pl.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "\n",
    "# reshape the data to the shape (n_samples, n_features) -- required for scikit-learn\n",
    "X = peak_heights.reshape([-1,1])\n",
    "# run k-means clustering\n",
    "km = KMeans(n_clusters=n_clusters).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the nerve and the peaks colored by cluster\n",
    "pl.figure(3)\n",
    "pl.plot(nerve, color='gray', lw=1)\n",
    "pl.scatter(peak_idxs, peak_heights, c=km.labels_, s=20, zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with your clusters defined, let's look at the instantaneous firing rate of one of the clusters. \n",
    "\n",
    "(Note: I am not suggesting that a particular unit's IFR should be of interest; but if this makes sense you now know how to isolate a particular cluster as well as make a plot of IFR.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out cluster 3\n",
    "cls3_tms = []\n",
    "cls3_amp = []\n",
    "\n",
    "for i in range(len(peak_idxs)):\n",
    "    if(km.labels_[i] == 3):\n",
    "        cls3_tms.append(peak_idxs[i])\n",
    "        cls3_amp.append(peak_heights[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantaneous firing rate is the reciprocal of the interval\n",
    "# np.diff is an array of the differences between the values of your array.\n",
    "ifr = 1/np.diff(cls3_tms)\n",
    "\n",
    "# let's call the time coords the average times of the peaks in question\n",
    "ifr_t = []\n",
    "for i in range(len(cls3_tms)):\n",
    "    if(i+1 < len(cls3_tms)):\n",
    "        ifr_t.append( (cls3_tms[i] + cls3_tms[i+1]) / 2.0 )\n",
    "\n",
    "pl.figure(4)\n",
    "\n",
    "ax1 = pl.subplot(211)\n",
    "pl.plot(ifr_t, ifr)\n",
    "\n",
    "ax2 = pl.subplot(212, sharex=ax1)\n",
    "pl.plot(nerve, color='gray', lw=1)\n",
    "pl.scatter(cls3_tms, cls3_amp, s=20, zorder=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
